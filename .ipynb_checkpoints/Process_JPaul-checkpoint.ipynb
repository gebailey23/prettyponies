{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# JPAULS IPYTHON NOTEBOOK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Does the necessary imports!\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Gets main page's HTML\n",
    "mainpagelink = 'http://racingchannel.com/results_archive.php'\n",
    "mainpagehtml = requests.get(mainpagelink).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Aqueduct</th>\n",
       "      <td>AQU</td>\n",
       "      <td>http://racingchannel.com//archives/AQU/default...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arlington Park</th>\n",
       "      <td>ARL</td>\n",
       "      <td>http://racingchannel.com//archives/ARL/default...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Australian Racing</th>\n",
       "      <td>AU1</td>\n",
       "      <td>http://racingchannel.com//archives/AU1/default...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Australian Racing - B</th>\n",
       "      <td>AU2</td>\n",
       "      <td>http://racingchannel.com//archives/AU2/default...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Australian Racing - C</th>\n",
       "      <td>AU3</td>\n",
       "      <td>http://racingchannel.com//archives/AU3/default...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      code                                               link\n",
       "Aqueduct               AQU  http://racingchannel.com//archives/AQU/default...\n",
       "Arlington Park         ARL  http://racingchannel.com//archives/ARL/default...\n",
       "Australian Racing      AU1  http://racingchannel.com//archives/AU1/default...\n",
       "Australian Racing - B  AU2  http://racingchannel.com//archives/AU2/default...\n",
       "Australian Racing - C  AU3  http://racingchannel.com//archives/AU3/default..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gets list of racetracks, racetrackcodes, and creates a dict of the two (can flip the order if necessary)\n",
    "racetrackshtmllst = BeautifulSoup(mainpagehtml, 'html.parser').body.table.findAll('tr')[4].findAll('td')\n",
    "tracks = []\n",
    "trackcodes = []\n",
    "trackdatalinks = []\n",
    "for tracklst in racetrackshtmllst:\n",
    "    tracklinks = tracklst.findAll('a')\n",
    "    for link in tracklinks:\n",
    "        #print link.get('href').encode('ascii')\n",
    "        trackdatalinks.append('http://racingchannel.com/'  + link.get('href').encode('ascii'))\n",
    "        trackcodes.append(link.get('href')[10:13].encode('ascii'))\n",
    "        tracks.append(link.text.encode('ascii'))\n",
    "tracks[1] = 'Arlington Park'\n",
    "# print tracks\n",
    "# print '\\n\\n'\n",
    "# print trackcodes\n",
    "# print '\\n\\n'\n",
    "trackcodedict = dict(zip(tracks, trackcodes))\n",
    "tracklinkdict = dict(zip(tracks, trackdatalinks))\n",
    "# print '\\n\\n'\n",
    "trackinfodf = pd.DataFrame(index=tracks)\n",
    "trackinfodf['code'] = trackcodes\n",
    "trackinfodf['link'] = trackdatalinks\n",
    "trackinfodf.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://racingchannel.com//archives/AQU/default.html\n",
      "http://racingchannel.com//archives/ARL/default.html\n",
      "http://racingchannel.com//archives/AU1/default.html\n",
      "http://racingchannel.com//archives/AU2/default.html\n",
      "http://racingchannel.com//archives/AU3/default.html\n",
      "http://racingchannel.com//archives/BAY/default.html\n",
      "http://racingchannel.com//archives/BEL/default.html\n",
      "http://racingchannel.com//archives/BEU/default.html\n",
      "http://racingchannel.com//archives/CAL/default.html\n",
      "http://racingchannel.com//archives/CAM/default.html\n",
      "http://racingchannel.com//archives/CAN/default.html\n",
      "http://racingchannel.com//archives/CTN/default.html\n",
      "http://racingchannel.com//archives/CHU/default.html\n",
      "http://racingchannel.com//archives/COL/default.html\n",
      "http://racingchannel.com//archives/DDN/default.html\n",
      "http://racingchannel.com//archives/DEL/default.html\n",
      "http://racingchannel.com//archives/DPK/default.html\n",
      "http://racingchannel.com//archives/ELL/default.html\n",
      "http://racingchannel.com//archives/EMD/default.html\n",
      "http://racingchannel.com//archives/EVN/default.html\n",
      "http://racingchannel.com//archives/FGD/default.html\n",
      "http://racingchannel.com//archives/FMT/default.html\n",
      "http://racingchannel.com//archives/FLX/default.html\n",
      "http://racingchannel.com//archives/FLK/default.html\n",
      "http://racingchannel.com//archives/FTE/default.html\n",
      "http://racingchannel.com//archives/GOL/default.html\n",
      "http://racingchannel.com//archives/GB1/default.html\n",
      "http://racingchannel.com//archives/GB2/default.html\n",
      "http://racingchannel.com//archives/GLD/default.html\n",
      "http://racingchannel.com//archives/GUL/default.html\n",
      "http://racingchannel.com//archives/HAS/default.html\n",
      "http://racingchannel.com//archives/HAW/default.html\n",
      "http://racingchannel.com//archives/HPX/default.html\n",
      "http://racingchannel.com//archives/HOO/default.html\n",
      "http://racingchannel.com//archives/IND/default.html\n",
      "http://racingchannel.com//archives/KND/default.html\n",
      "http://racingchannel.com//archives/KEN/default.html\n",
      "http://racingchannel.com//archives/LAU/default.html\n",
      "http://racingchannel.com//archives/LDN/default.html\n",
      "http://racingchannel.com//archives/LON/default.html\n",
      "http://racingchannel.com//archives/LOS/default.html\n",
      "http://racingchannel.com//archives/MDL/default.html\n",
      "http://racingchannel.com//archives/MON/default.html\n",
      "http://racingchannel.com//archives/MTR/default.html\n",
      "http://racingchannel.com//archives/NCF/default.html\n",
      "http://racingchannel.com//archives/OAK/default.html\n",
      "http://racingchannel.com//archives/PEN/default.html\n",
      "http://racingchannel.com//archives/PHI/default.html\n",
      "http://racingchannel.com//archives/PIM/default.html\n",
      "http://racingchannel.com//archives/POR/default.html\n",
      "http://racingchannel.com//archives/PRM/default.html\n",
      "http://racingchannel.com//archives/REM/default.html\n",
      "http://racingchannel.com//archives/RET/default.html\n",
      "http://racingchannel.com//archives/RIV/default.html\n",
      "http://racingchannel.com//archives/SAM/default.html\n",
      "http://racingchannel.com//archives/SAN/default.html\n",
      "http://racingchannel.com//archives/SGA/default.html\n",
      "http://racingchannel.com//archives/ZA1/default.html\n",
      "http://racingchannel.com//archives/ZA2/default.html\n",
      "http://racingchannel.com//archives/SPT/default.html\n",
      "http://racingchannel.com//archives/SUF/default.html\n",
      "http://racingchannel.com//archives/TAM/default.html\n",
      "http://racingchannel.com//archives/THI/default.html\n",
      "http://racingchannel.com//archives/TIM/default.html\n",
      "http://racingchannel.com//archives/PAR/default.html\n",
      "http://racingchannel.com//archives/TUR/default.html\n",
      "http://racingchannel.com//archives/WOB/default.html\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>link</th>\n",
       "      <th>track_html</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Aqueduct</th>\n",
       "      <td>AQU</td>\n",
       "      <td>http://racingchannel.com//archives/AQU/default...</td>\n",
       "      <td>&lt;html&gt;\n",
       "&lt;head&gt;&lt;title&gt;Aqueduct Results Archive&lt;/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arlington Park</th>\n",
       "      <td>ARL</td>\n",
       "      <td>http://racingchannel.com//archives/ARL/default...</td>\n",
       "      <td>&lt;html&gt;\n",
       "&lt;head&gt;&lt;title&gt;Arlington Results Archive&lt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Australian Racing</th>\n",
       "      <td>AU1</td>\n",
       "      <td>http://racingchannel.com//archives/AU1/default...</td>\n",
       "      <td>&lt;html&gt;\n",
       "&lt;head&gt;&lt;title&gt;Australia - A Results Arch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Australian Racing - B</th>\n",
       "      <td>AU2</td>\n",
       "      <td>http://racingchannel.com//archives/AU2/default...</td>\n",
       "      <td>&lt;html&gt;\n",
       "&lt;head&gt;&lt;title&gt;Australia - B Results Arch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Australian Racing - C</th>\n",
       "      <td>AU3</td>\n",
       "      <td>http://racingchannel.com//archives/AU3/default...</td>\n",
       "      <td>&lt;html&gt;\n",
       "&lt;head&gt;&lt;title&gt; Results Archive&lt;/title&gt;&lt;/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bay Meadows</th>\n",
       "      <td>BAY</td>\n",
       "      <td>http://racingchannel.com//archives/BAY/default...</td>\n",
       "      <td>&lt;html&gt;\n",
       "&lt;head&gt;&lt;title&gt;Bay Meadows Results Archiv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Belmont Park</th>\n",
       "      <td>BEL</td>\n",
       "      <td>http://racingchannel.com//archives/BEL/default...</td>\n",
       "      <td>&lt;html&gt;\n",
       "&lt;head&gt;&lt;title&gt;Belmont Results Archive&lt;/t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Beulah Park</th>\n",
       "      <td>BEU</td>\n",
       "      <td>http://racingchannel.com//archives/BEU/default...</td>\n",
       "      <td>&lt;html&gt;\n",
       "&lt;head&gt;&lt;title&gt;Beulah Results Archive&lt;/ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Calder Race Course</th>\n",
       "      <td>CAL</td>\n",
       "      <td>http://racingchannel.com//archives/CAL/default...</td>\n",
       "      <td>&lt;html&gt;\n",
       "&lt;head&gt;&lt;title&gt;Calder Results Archive&lt;/ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Camarero</th>\n",
       "      <td>CAM</td>\n",
       "      <td>http://racingchannel.com//archives/CAM/default...</td>\n",
       "      <td>&lt;html&gt;\n",
       "&lt;head&gt;&lt;title&gt; Results Archive&lt;/title&gt;&lt;/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      code                                               link  \\\n",
       "Aqueduct               AQU  http://racingchannel.com//archives/AQU/default...   \n",
       "Arlington Park         ARL  http://racingchannel.com//archives/ARL/default...   \n",
       "Australian Racing      AU1  http://racingchannel.com//archives/AU1/default...   \n",
       "Australian Racing - B  AU2  http://racingchannel.com//archives/AU2/default...   \n",
       "Australian Racing - C  AU3  http://racingchannel.com//archives/AU3/default...   \n",
       "Bay Meadows            BAY  http://racingchannel.com//archives/BAY/default...   \n",
       "Belmont Park           BEL  http://racingchannel.com//archives/BEL/default...   \n",
       "Beulah Park            BEU  http://racingchannel.com//archives/BEU/default...   \n",
       "Calder Race Course     CAL  http://racingchannel.com//archives/CAL/default...   \n",
       "Camarero               CAM  http://racingchannel.com//archives/CAM/default...   \n",
       "\n",
       "                                                              track_html  \n",
       "Aqueduct               <html>\n",
       "<head><title>Aqueduct Results Archive</...  \n",
       "Arlington Park         <html>\n",
       "<head><title>Arlington Results Archive<...  \n",
       "Australian Racing      <html>\n",
       "<head><title>Australia - A Results Arch...  \n",
       "Australian Racing - B  <html>\n",
       "<head><title>Australia - B Results Arch...  \n",
       "Australian Racing - C  <html>\n",
       "<head><title> Results Archive</title></...  \n",
       "Bay Meadows            <html>\n",
       "<head><title>Bay Meadows Results Archiv...  \n",
       "Belmont Park           <html>\n",
       "<head><title>Belmont Results Archive</t...  \n",
       "Beulah Park            <html>\n",
       "<head><title>Beulah Results Archive</ti...  \n",
       "Calder Race Course     <html>\n",
       "<head><title>Calder Results Archive</ti...  \n",
       "Camarero               <html>\n",
       "<head><title> Results Archive</title></...  "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stores the html of all track info pages\n",
    "\n",
    "#############################################################\n",
    "## SKIP THIS IF TEMPDATA ALREADY HAS TRACKINFO.CSV IN IT!!!! ##\n",
    "#############################################################\n",
    "\n",
    "\n",
    "htmloftracks = []\n",
    "for link in trackdatalinks:\n",
    "    htmloftracks.append(BeautifulSoup(requests.get(link).text))\n",
    "    print link\n",
    "    time.sleep(5)\n",
    "\n",
    "trackinfodf['track_html'] = htmloftracks\n",
    "trackinfodf.head(10)\n",
    "\n",
    "# Stores track codes and links in csv\n",
    "trackinfodf.to_csv('tempdata/trackinfo.csv', index_label='name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>link</th>\n",
       "      <th>track_html</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Aqueduct</th>\n",
       "      <td>AQU</td>\n",
       "      <td>http://racingchannel.com//archives/AQU/default...</td>\n",
       "      <td>&lt;html&gt;\n",
       "&lt;head&gt;&lt;title&gt;Aqueduct Results Archive&lt;/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arlington Park</th>\n",
       "      <td>ARL</td>\n",
       "      <td>http://racingchannel.com//archives/ARL/default...</td>\n",
       "      <td>&lt;html&gt;\n",
       "&lt;head&gt;&lt;title&gt;Arlington Results Archive&lt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Australian Racing</th>\n",
       "      <td>AU1</td>\n",
       "      <td>http://racingchannel.com//archives/AU1/default...</td>\n",
       "      <td>&lt;html&gt;\n",
       "&lt;head&gt;&lt;title&gt;Australia - A Results Arch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Australian Racing - B</th>\n",
       "      <td>AU2</td>\n",
       "      <td>http://racingchannel.com//archives/AU2/default...</td>\n",
       "      <td>&lt;html&gt;\n",
       "&lt;head&gt;&lt;title&gt;Australia - B Results Arch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Australian Racing - C</th>\n",
       "      <td>AU3</td>\n",
       "      <td>http://racingchannel.com//archives/AU3/default...</td>\n",
       "      <td>&lt;html&gt;\n",
       "&lt;head&gt;&lt;title&gt; Results Archive&lt;/title&gt;&lt;/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      code                                               link  \\\n",
       "name                                                                            \n",
       "Aqueduct               AQU  http://racingchannel.com//archives/AQU/default...   \n",
       "Arlington Park         ARL  http://racingchannel.com//archives/ARL/default...   \n",
       "Australian Racing      AU1  http://racingchannel.com//archives/AU1/default...   \n",
       "Australian Racing - B  AU2  http://racingchannel.com//archives/AU2/default...   \n",
       "Australian Racing - C  AU3  http://racingchannel.com//archives/AU3/default...   \n",
       "\n",
       "                                                              track_html  \n",
       "name                                                                      \n",
       "Aqueduct               <html>\n",
       "<head><title>Aqueduct Results Archive</...  \n",
       "Arlington Park         <html>\n",
       "<head><title>Arlington Results Archive<...  \n",
       "Australian Racing      <html>\n",
       "<head><title>Australia - A Results Arch...  \n",
       "Australian Racing - B  <html>\n",
       "<head><title>Australia - B Results Arch...  \n",
       "Australian Racing - C  <html>\n",
       "<head><title> Results Archive</title></...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loads trackinfodf from the csv in tempdata\n",
    "try:\n",
    "    del trackinfodf\n",
    "except:\n",
    "    pass\n",
    "trackinfodf = pd.read_csv('tempdata/trackinfo.csv', index_col='name')\n",
    "trackinfodf['track_html'] = trackinfodf['track_html'].apply(lambda h:BeautifulSoup(h, 'html.parser'))\n",
    "trackinfodf.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# For each track rip the years and months that the track had races ran on it\n",
    "tracksoups = trackinfodf['track_html']\n",
    "yrmonthdicts_by_track = []\n",
    "for soup in tracksoups:\n",
    "    try:\n",
    "        soup = soup.body.center.findAll('table')[1].tr.findAll('td')\n",
    "    except:\n",
    "        soup = soup.body.center.findAll('table')[0].tr.findAll('td')\n",
    "    years = []\n",
    "    yrmonths_for_track = []\n",
    "    for col in soup:\n",
    "        year = col.text.encode('ascii')[:4]\n",
    "        years.append(year)\n",
    "        months = [elem.get('href').encode('ascii')[19:21] for elem in col.findAll('a')]\n",
    "        yrmonths_for_track.append({year: months})\n",
    "\n",
    "    yrmonthdicts_by_track.append(yrmonths_for_track)\n",
    "biggie = dict(zip(trackcodes,yrmonthdicts_by_track))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AQU\n",
      "0\n",
      "ARL\n",
      "0\n",
      "AU1\n",
      "0\n",
      "AU2\n",
      "0\n",
      "AU3\n",
      "0\n",
      "BAY\n",
      "0\n",
      "BEL\n",
      "0\n",
      "BEU\n",
      "0\n",
      "CAL\n",
      "0\n",
      "CAM\n",
      "0\n",
      "CAN\n",
      "0\n",
      "CHU\n",
      "0\n",
      "COL\n",
      "0\n",
      "CTN\n",
      "0\n",
      "DDN\n",
      "0\n",
      "DEL\n",
      "0\n",
      "DPK\n",
      "0\n",
      "ELL\n",
      "0\n",
      "EMD\n",
      "0\n",
      "EVN\n",
      "0\n",
      "FGD\n",
      "0\n",
      "FLK\n",
      "0\n",
      "FLX\n",
      "0\n",
      "FMT\n",
      "0\n",
      "FTE\n",
      "0\n",
      "GB1\n",
      "0\n",
      "GB2\n",
      "0\n",
      "GLD\n",
      "0\n",
      "GOL\n",
      "0\n",
      "GUL\n",
      "0\n",
      "HAS\n",
      "0\n",
      "HAW\n",
      "0\n",
      "HOO\n",
      "0\n",
      "HPX\n",
      "0\n",
      "IND\n",
      "0\n",
      "KEN\n",
      "0\n",
      "KND\n",
      "0\n",
      "LAU\n",
      "0\n",
      "LDN\n",
      "0\n",
      "LON\n",
      "0\n",
      "LOS\n",
      "0\n",
      "MDL\n",
      "0\n",
      "MON\n",
      "0\n",
      "MTR\n",
      "0\n",
      "NCF\n",
      "0\n",
      "OAK\n",
      "0\n",
      "PAR\n",
      "10\n",
      "11\n",
      "12\n",
      "04\n",
      "05\n",
      "10\n",
      "11\n",
      "12\n",
      "04\n",
      "05\n",
      "10\n",
      "11\n",
      "12\n",
      "01\n",
      "02\n",
      "03\n",
      "04\n",
      "05\n",
      "09\n",
      "10\n",
      "11\n",
      "12\n",
      "01\n",
      "02\n",
      "03\n",
      "04\n",
      "05\n",
      "09\n",
      "10\n",
      "11\n",
      "12\n",
      "01\n",
      "02\n",
      "03\n",
      "04\n",
      "05\n",
      "09\n",
      "10\n",
      "11\n",
      "12\n",
      "01\n",
      "02\n",
      "03\n",
      "04\n",
      "05\n",
      "10\n",
      "11\n",
      "12\n",
      "01\n",
      "02\n",
      "03\n",
      "04\n",
      "05\n",
      "09\n",
      "10\n",
      "11\n",
      "12\n",
      "01\n",
      "02\n",
      "03\n",
      "04\n",
      "05\n",
      "10\n",
      "11\n",
      "12\n",
      "01\n",
      "02\n",
      "03\n",
      "04\n",
      "05\n",
      "10\n",
      "11\n",
      "12\n",
      "01\n",
      "02\n",
      "03\n",
      "04\n",
      "05\n",
      "10\n",
      "11\n",
      "12\n",
      "01\n",
      "02\n",
      "03\n",
      "04\n",
      "05\n",
      "10\n",
      "11\n",
      "12\n",
      "01\n",
      "02\n",
      "03\n",
      "04\n",
      "05\n",
      "10\n",
      "11\n",
      "12\n",
      "01\n",
      "02\n",
      "03\n",
      "04\n",
      "05\n",
      "10\n",
      "11\n",
      "12\n",
      "01\n",
      "02\n",
      "03\n",
      "04\n",
      "05\n",
      "10\n",
      "11\n",
      "12\n",
      "01\n",
      "02\n",
      "03\n",
      "04\n",
      "05\n",
      "10\n",
      "11\n",
      "12\n",
      "01\n",
      "02\n",
      "03\n",
      "04\n",
      "05\n",
      "10\n",
      "11\n",
      "03\n",
      "04\n",
      "05\n",
      "10\n",
      "11\n",
      "2379\n",
      "PEN\n",
      "2379\n",
      "PHI\n",
      "2379\n",
      "PIM\n",
      "2379\n",
      "POR\n",
      "2379\n",
      "PRM\n",
      "2379\n",
      "REM\n",
      "03\n",
      "04\n",
      "05\n",
      "06\n",
      "08\n",
      "09\n",
      "10\n",
      "11\n",
      "12\n",
      "03\n",
      "04\n",
      "05\n",
      "08\n",
      "09\n",
      "10\n",
      "11\n",
      "2605\n",
      "RET\n",
      "08\n",
      "09\n",
      "10\n",
      "07\n",
      "08\n",
      "09\n",
      "10\n",
      "08\n",
      "09\n",
      "10\n",
      "05\n",
      "06\n",
      "08\n",
      "09\n",
      "10\n",
      "08\n",
      "09\n",
      "10\n",
      "08\n",
      "09\n",
      "10\n",
      "07\n",
      "08\n",
      "09\n",
      "04\n",
      "05\n",
      "06\n",
      "08\n",
      "09\n",
      "10\n",
      "04\n",
      "05\n",
      "06\n",
      "08\n",
      "09\n",
      "10\n",
      "11\n",
      "05\n",
      "06\n",
      "09\n",
      "10\n",
      "11\n",
      "04\n",
      "08\n",
      "09\n",
      "10\n",
      "11\n",
      "12\n",
      "01\n",
      "02\n",
      "08\n",
      "09\n",
      "10\n",
      "11\n",
      "09\n",
      "10\n",
      "07\n",
      "08\n",
      "09\n",
      "10\n",
      "11\n",
      "06\n",
      "07\n",
      "08\n",
      "10\n",
      "11\n",
      "12\n",
      "06\n",
      "07\n",
      "08\n",
      "10\n",
      "11\n",
      "12\n",
      "06\n",
      "07\n",
      "08\n",
      "09\n",
      "10\n",
      "11\n",
      "06\n",
      "07\n",
      "08\n",
      "09\n",
      "10\n",
      "3467\n",
      "RIV\n",
      "04\n",
      "04\n",
      "05\n",
      "04\n",
      "05\n",
      "06\n",
      "07\n",
      "08\n",
      "04\n",
      "05\n",
      "06\n",
      "07\n",
      "08\n",
      "04\n",
      "05\n",
      "06\n",
      "07\n",
      "08\n",
      "04\n",
      "05\n",
      "06\n",
      "07\n",
      "08\n",
      "09\n",
      "04\n",
      "05\n",
      "06\n",
      "07\n",
      "08\n",
      "09\n",
      "04\n",
      "05\n",
      "06\n",
      "07\n",
      "08\n",
      "09\n",
      "04\n",
      "05\n",
      "06\n",
      "07\n",
      "08\n",
      "09\n",
      "05\n",
      "06\n",
      "07\n",
      "08\n",
      "09\n",
      "04\n",
      "05\n",
      "06\n",
      "07\n",
      "08\n",
      "09\n",
      "05\n",
      "06\n",
      "07\n",
      "08\n",
      "09\n",
      "3914\n",
      "SAM\n",
      "10\n",
      "11\n",
      "12\n",
      "10\n",
      "11\n",
      "12\n",
      "11\n",
      "12\n",
      "01\n",
      "02\n",
      "03\n",
      "11\n",
      "12\n",
      "01\n",
      "02\n",
      "03\n",
      "11\n",
      "12\n",
      "01\n",
      "02\n",
      "03\n",
      "10\n",
      "11\n",
      "12\n",
      "01\n",
      "02\n",
      "03\n",
      "04\n",
      "10\n",
      "11\n",
      "12\n",
      "01\n",
      "02\n",
      "03\n",
      "04\n",
      "08\n",
      "09\n",
      "10\n",
      "11\n",
      "12\n",
      "01\n",
      "02\n",
      "03\n",
      "04\n",
      "06\n",
      "07\n",
      "08\n",
      "09\n",
      "11\n",
      "12\n",
      "01\n",
      "02\n",
      "03\n",
      "04\n",
      "06\n",
      "07\n",
      "08\n",
      "09\n",
      "11\n",
      "12\n",
      "01\n",
      "02\n",
      "03\n",
      "04\n",
      "05\n",
      "06\n",
      "07\n",
      "08\n",
      "11\n",
      "12\n",
      "01\n",
      "02\n",
      "03\n",
      "04\n",
      "05\n",
      "06\n",
      "07\n",
      "08\n",
      "01\n",
      "02\n",
      "03\n",
      "04\n",
      "05\n",
      "01\n",
      "02\n",
      "03\n",
      "04\n",
      "05\n",
      "01\n",
      "02\n",
      "03\n",
      "04\n",
      "05\n",
      "01\n",
      "02\n",
      "03\n",
      "04\n",
      "05\n",
      "01\n",
      "02\n",
      "03\n",
      "04\n",
      "05\n",
      "5107\n",
      "SAN\n",
      "09\n",
      "10\n",
      "11\n",
      "12\n",
      "04\n",
      "09\n",
      "10\n",
      "11\n",
      "12\n",
      "04\n",
      "10\n",
      "11\n",
      "12\n",
      "01\n",
      "02\n",
      "03\n",
      "04\n",
      "09\n",
      "10\n",
      "11\n",
      "12\n",
      "01\n",
      "02\n",
      "03\n",
      "04\n",
      "10\n",
      "11\n",
      "12\n",
      "01\n",
      "02\n",
      "03\n",
      "04\n",
      "09\n",
      "10\n",
      "11\n",
      "12\n",
      "01\n",
      "02\n",
      "03\n",
      "04\n",
      "09\n",
      "10\n",
      "12\n",
      "01\n",
      "02\n",
      "03\n",
      "04\n",
      "09\n",
      "10\n",
      "11\n",
      "12\n",
      "01\n",
      "02\n",
      "03\n",
      "04\n",
      "09\n",
      "10\n",
      "12\n",
      "01\n",
      "02\n",
      "03\n",
      "04\n",
      "09\n",
      "10\n",
      "11\n",
      "12\n",
      "01\n",
      "02\n",
      "03\n",
      "04\n",
      "09\n",
      "10\n",
      "12\n",
      "01\n",
      "02\n",
      "03\n",
      "04\n",
      "09\n",
      "10\n",
      "11\n",
      "01\n",
      "02\n",
      "03\n",
      "04\n",
      "12\n",
      "01\n",
      "02\n",
      "03\n",
      "04\n",
      "09\n",
      "10\n",
      "11\n",
      "12\n",
      "01\n",
      "02\n",
      "03\n",
      "04\n",
      "09\n",
      "10\n",
      "11\n",
      "12\n",
      "01\n",
      "02\n",
      "03\n",
      "04\n",
      "09\n",
      "10\n",
      "11\n",
      "12\n",
      "01\n",
      "02\n",
      "03\n",
      "04\n",
      "05\n",
      "06\n",
      "09\n",
      "10\n",
      "11\n",
      "03\n",
      "04\n",
      "05\n",
      "06\n",
      "09\n",
      "10\n",
      "6752\n",
      "SGA\n",
      "08\n",
      "09\n",
      "07\n",
      "08\n",
      "09\n",
      "07\n",
      "08\n",
      "09\n",
      "07\n",
      "08\n",
      "09\n",
      "07\n",
      "08\n",
      "09\n",
      "07\n",
      "08\n",
      "09\n",
      "07\n",
      "08\n",
      "09\n",
      "07\n",
      "08\n",
      "09\n",
      "07\n",
      "08\n",
      "09\n",
      "07\n",
      "08\n",
      "09\n",
      "07\n",
      "08\n",
      "09\n",
      "07\n",
      "08\n",
      "09\n",
      "07\n",
      "08\n",
      "09\n",
      "07\n",
      "08\n",
      "09\n",
      "07\n",
      "08\n",
      "09\n",
      "07\n",
      "08\n",
      "09\n",
      "07\n",
      "08\n",
      "09\n",
      "07\n",
      "08\n",
      "09\n",
      "7371\n",
      "SPT\n",
      "04\n",
      "05\n",
      "06\n",
      "04\n",
      "05\n",
      "03\n",
      "04\n",
      "03\n",
      "04\n",
      "7515\n",
      "SUF\n",
      "09\n",
      "10\n",
      "11\n",
      "12\n",
      "04\n",
      "05\n",
      "06\n",
      "09\n",
      "10\n",
      "11\n",
      "12\n",
      "04\n",
      "05\n",
      "06\n",
      "09\n",
      "10\n",
      "11\n",
      "12\n",
      "01\n",
      "02\n",
      "03\n",
      "04\n",
      "05\n",
      "06\n",
      "09\n",
      "10\n",
      "11\n",
      "12\n",
      "01\n",
      "02\n",
      "03\n",
      "04\n",
      "05\n",
      "06\n",
      "09\n",
      "10\n",
      "11\n",
      "12\n",
      "01\n",
      "02\n",
      "03\n",
      "04\n",
      "05\n",
      "06\n",
      "07\n",
      "08\n",
      "09\n",
      "10\n",
      "05\n",
      "06\n",
      "07\n",
      "08\n",
      "09\n",
      "10\n",
      "11\n",
      "04\n",
      "05\n",
      "06\n",
      "07\n",
      "08\n",
      "09\n",
      "10\n",
      "11\n",
      "05\n",
      "06\n",
      "07\n",
      "08\n",
      "09\n",
      "10\n",
      "11\n",
      "05\n",
      "06\n",
      "07\n",
      "08\n",
      "09\n",
      "10\n",
      "11\n",
      "05\n",
      "06\n",
      "07\n",
      "08\n",
      "09\n",
      "10\n",
      "11\n",
      "05\n",
      "06\n",
      "07\n",
      "08\n",
      "09\n",
      "10\n",
      "11\n",
      "05\n",
      "06\n",
      "07\n",
      "08\n",
      "09\n",
      "10\n",
      "11\n",
      "05\n",
      "06\n",
      "07\n",
      "08\n",
      "09\n",
      "10\n",
      "11\n",
      "06\n",
      "07\n",
      "08\n",
      "09\n",
      "10\n",
      "11\n",
      "06\n",
      "07\n",
      "08\n",
      "09\n",
      "10\n",
      "11\n",
      "05\n",
      "06\n",
      "07\n",
      "08\n",
      "09\n",
      "10\n",
      "09\n",
      "10\n",
      "9184\n",
      "TAM\n",
      "12\n",
      "04\n",
      "05\n",
      "12\n",
      "04\n",
      "05\n",
      "01\n",
      "02\n",
      "03\n",
      "04\n",
      "05\n",
      "12\n",
      "01\n",
      "02\n",
      "03\n",
      "04\n",
      "12\n",
      "01\n",
      "02\n",
      "03\n",
      "04\n",
      "05\n",
      "12\n",
      "01\n",
      "02\n",
      "03\n",
      "04\n",
      "05\n",
      "12\n",
      "01\n",
      "02\n",
      "03\n",
      "04\n",
      "05\n",
      "12\n",
      "01\n",
      "02\n",
      "03\n",
      "04\n",
      "05\n",
      "12\n",
      "01\n",
      "02\n",
      "03\n",
      "04\n",
      "05\n",
      "12\n",
      "01\n",
      "02\n",
      "03\n",
      "04\n",
      "05\n",
      "12\n",
      "01\n",
      "02\n",
      "03\n",
      "04\n",
      "05\n",
      "12\n",
      "01\n",
      "02\n",
      "03\n",
      "04\n",
      "05\n",
      "12\n",
      "01\n",
      "02\n",
      "03\n",
      "04\n",
      "05\n",
      "12\n",
      "01\n",
      "02\n",
      "03\n",
      "04\n",
      "05\n",
      "12\n",
      "01\n",
      "02\n",
      "03\n",
      "04\n",
      "05\n",
      "12\n",
      "01\n",
      "02\n",
      "03\n",
      "04\n",
      "05\n",
      "06\n",
      "07\n",
      "11\n",
      "12\n",
      "01\n",
      "02\n",
      "03\n",
      "04\n",
      "05\n",
      "06\n",
      "07\n",
      "10561\n",
      "THI\n",
      "08\n",
      "09\n",
      "10\n",
      "11\n",
      "12\n",
      "04\n",
      "05\n",
      "06\n",
      "07\n",
      "08\n",
      "09\n",
      "10\n",
      "11\n",
      "12\n",
      "04\n",
      "05\n",
      "06\n",
      "07\n",
      "08\n",
      "09\n",
      "10\n",
      "11\n",
      "12\n",
      "01\n",
      "02\n",
      "03\n",
      "04\n",
      "05\n",
      "06\n",
      "07\n",
      "08\n",
      "09\n",
      "10\n",
      "11\n",
      "12\n",
      "01\n",
      "02\n",
      "03\n",
      "04\n",
      "05\n",
      "06\n",
      "07\n",
      "08\n",
      "09\n",
      "10\n",
      "11\n",
      "12\n",
      "01\n",
      "02\n",
      "03\n",
      "04\n",
      "05\n",
      "06\n",
      "07\n",
      "08\n",
      "09\n",
      "10\n",
      "11\n",
      "12\n",
      "01\n",
      "04\n",
      "05\n",
      "06\n",
      "07\n",
      "08\n",
      "09\n",
      "10\n",
      "11\n",
      "12\n",
      "04\n",
      "05\n",
      "06\n",
      "07\n",
      "08\n",
      "09\n",
      "10\n",
      "11\n",
      "12\n",
      "04\n",
      "05\n",
      "06\n",
      "07\n",
      "08\n",
      "09\n",
      "10\n",
      "11\n",
      "04\n",
      "05\n",
      "06\n",
      "07\n",
      "08\n",
      "09\n",
      "10\n",
      "11\n",
      "05\n",
      "06\n",
      "07\n",
      "08\n",
      "09\n",
      "10\n",
      "04\n",
      "05\n",
      "06\n",
      "07\n",
      "08\n",
      "09\n",
      "10\n",
      "04\n",
      "05\n",
      "06\n",
      "07\n",
      "08\n",
      "09\n",
      "10\n",
      "11\n",
      "04\n",
      "05\n",
      "06\n",
      "07\n",
      "08\n",
      "09\n",
      "10\n",
      "11\n",
      "05\n",
      "06\n",
      "07\n",
      "08\n",
      "09\n",
      "10\n",
      "11\n",
      "04\n",
      "05\n",
      "06\n",
      "07\n",
      "08\n",
      "09\n",
      "10\n",
      "11\n",
      "04\n",
      "05\n",
      "06\n",
      "07\n",
      "08\n",
      "09\n",
      "10\n",
      "13227\n",
      "TIM\n",
      "08\n",
      "09\n",
      "08\n",
      "09\n",
      "08\n",
      "09\n",
      "08\n",
      "09\n",
      "08\n",
      "09\n",
      "08\n",
      "09\n",
      "08\n",
      "09\n",
      "08\n",
      "09\n",
      "08\n",
      "09\n",
      "08\n",
      "09\n",
      "08\n",
      "09\n",
      "08\n",
      "09\n",
      "08\n",
      "09\n",
      "08\n",
      "09\n",
      "08\n",
      "09\n",
      "08\n",
      "09\n",
      "08\n",
      "09\n",
      "13356\n",
      "TUR\n",
      "09\n",
      "10\n",
      "11\n",
      "12\n",
      "09\n",
      "10\n",
      "11\n",
      "12\n",
      "09\n",
      "10\n",
      "11\n",
      "12\n",
      "01\n",
      "02\n",
      "03\n",
      "04\n",
      "09\n",
      "10\n",
      "11\n",
      "12\n",
      "01\n",
      "02\n",
      "03\n",
      "04\n",
      "09\n",
      "10\n",
      "12\n",
      "01\n",
      "02\n",
      "03\n",
      "04\n",
      "09\n",
      "10\n",
      "11\n",
      "12\n",
      "01\n",
      "02\n",
      "03\n",
      "04\n",
      "09\n",
      "10\n",
      "11\n",
      "12\n",
      "01\n",
      "02\n",
      "03\n",
      "04\n",
      "09\n",
      "10\n",
      "11\n",
      "12\n",
      "01\n",
      "02\n",
      "03\n",
      "04\n",
      "09\n",
      "10\n",
      "11\n",
      "12\n",
      "01\n",
      "02\n",
      "03\n",
      "04\n",
      "09\n",
      "10\n",
      "11\n",
      "12\n",
      "01\n",
      "02\n",
      "03\n",
      "04\n",
      "09\n",
      "10\n",
      "11\n",
      "12\n",
      "01\n",
      "02\n",
      "03\n",
      "04\n",
      "09\n",
      "10\n",
      "11\n",
      "12\n",
      "01\n",
      "02\n",
      "03\n",
      "09\n",
      "10\n",
      "12\n",
      "01\n",
      "02\n",
      "03\n",
      "04\n",
      "09\n",
      "10\n",
      "12\n",
      "01\n",
      "02\n",
      "03\n",
      "04\n",
      "09\n",
      "11\n",
      "12\n",
      "01\n",
      "02\n",
      "03\n",
      "12\n",
      "01\n",
      "02\n",
      "03\n",
      "12\n",
      "01\n",
      "02\n",
      "03\n",
      "14802\n",
      "WOB\n",
      "08\n",
      "09\n",
      "10\n",
      "11\n",
      "12\n",
      "04\n",
      "05\n",
      "06\n",
      "07\n",
      "08\n",
      "09\n",
      "10\n",
      "11\n",
      "04\n",
      "05\n",
      "06\n",
      "07\n",
      "08\n",
      "09\n",
      "10\n",
      "11\n",
      "04\n",
      "05\n",
      "06\n",
      "07\n",
      "08\n",
      "09\n",
      "10\n",
      "11\n",
      "12\n",
      "03\n",
      "04\n",
      "05\n",
      "06\n",
      "07\n",
      "08\n",
      "09\n",
      "10\n",
      "11\n",
      "12\n",
      "03\n",
      "04\n",
      "05\n",
      "06\n",
      "07\n",
      "08\n",
      "09\n",
      "10\n",
      "11\n",
      "04\n",
      "05\n",
      "06\n",
      "07\n",
      "08\n",
      "09\n",
      "10\n",
      "11\n",
      "12\n",
      "04\n",
      "05\n",
      "06\n",
      "07\n",
      "08\n",
      "09\n",
      "10\n",
      "11\n",
      "12\n",
      "04\n",
      "05\n",
      "06\n",
      "07\n",
      "08\n",
      "09\n",
      "10\n",
      "11\n",
      "12\n",
      "03\n",
      "04\n",
      "05\n",
      "06\n",
      "07\n",
      "08\n",
      "09\n",
      "10\n",
      "11\n",
      "12\n",
      "04\n",
      "05\n",
      "06\n",
      "07\n",
      "08\n",
      "09\n",
      "10\n",
      "11\n",
      "12\n",
      "04\n",
      "05\n",
      "06\n",
      "07\n",
      "08\n",
      "09\n",
      "10\n",
      "11\n",
      "12\n",
      "04\n",
      "05\n",
      "06\n",
      "07\n",
      "08\n",
      "09\n",
      "10\n",
      "11\n",
      "12\n",
      "04\n",
      "05\n",
      "06\n",
      "07\n",
      "08\n",
      "09\n",
      "10\n",
      "11\n",
      "12\n",
      "04\n",
      "05\n",
      "06\n",
      "07\n",
      "08\n",
      "09\n",
      "10\n",
      "11\n",
      "12\n",
      "04\n",
      "05\n",
      "06\n",
      "07\n",
      "08\n",
      "09\n",
      "10\n",
      "11\n",
      "12\n",
      "04\n",
      "05\n",
      "06\n",
      "07\n",
      "08\n",
      "09\n",
      "10\n",
      "11\n",
      "12\n",
      "04\n",
      "05\n",
      "06\n",
      "07\n",
      "08\n",
      "09\n",
      "10\n",
      "11\n",
      "17473\n",
      "ZA1\n",
      "08\n",
      "09\n",
      "10\n",
      "11\n",
      "12\n",
      "03\n",
      "04\n",
      "05\n",
      "09\n",
      "10\n",
      "11\n",
      "12\n",
      "01\n",
      "02\n",
      "03\n",
      "04\n",
      "05\n",
      "09\n",
      "10\n",
      "11\n",
      "12\n",
      "01\n",
      "02\n",
      "03\n",
      "04\n",
      "05\n",
      "06\n",
      "07\n",
      "08\n",
      "09\n",
      "10\n",
      "11\n",
      "12\n",
      "01\n",
      "02\n",
      "03\n",
      "17633\n",
      "ZA2\n",
      "10\n",
      "17636\n",
      "17636\n",
      "CPU times: user 18.4 s, sys: 1.31 s, total: 19.7 s\n",
      "Wall time: 1h 8min 52s\n"
     ]
    }
   ],
   "source": [
    "# Scrapes all the days that the track was in operation for eah month, year, and track combo\n",
    "%%time\n",
    "tstorage = []\n",
    "trackday_lists = []\n",
    "for track in sorted(biggie.keys()):\n",
    "    print track\n",
    "    ystorage = []\n",
    "    for yeardict in biggie[track]:\n",
    "        mstorage = []\n",
    "        if (int(yeardict.keys()[0]) > 2013 and track == 'REM') or trackcodes.index(track) > trackcodes.index('REM'):\n",
    "            for month in yeardict.values()[0]:\n",
    "                print month\n",
    "                monthhtml = BeautifulSoup(requests.get('http://racingchannel.com/archives/{}/{}/{}/default.html'\\\n",
    "                                             .format(track,yeardict.keys()[0],month)).text, 'html.parser').body.center\n",
    "                try:\n",
    "                    soup = monthhtml.findAll('table')[1]\n",
    "                except:\n",
    "                    soup = monthhtml.findAll('table')[0]\n",
    "                days = [daytag.get('href')[29:31].encode('ascii') for daytag in soup.findAll('a')]\n",
    "                mo = daytag.get('href')[19:21].encode('ascii')\n",
    "                yr = daytag.get('href')[14:18].encode('ascii')\n",
    "                trk = daytag.get('href')[22:25].encode('ascii')\n",
    "                for day in days:\n",
    "                    trackday_lists.append([trk, yr, mo, day]) \n",
    "                time.sleep(2)\n",
    "                #print 'ya'\n",
    "            time.sleep(5)\n",
    "    \n",
    "    print len(trackday_lists)\n",
    "print len(trackday_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Was used to deal with two separate runs of the above, and making sure the main \n",
    "\n",
    "# print len(trackday_lists)\n",
    "# trackday_lists2 = trackday_lists\n",
    "# daydf2 = pd.DataFrame(trackday_lists2, columns=['track','year','month','day'])\n",
    "# daydf2.to_csv('tempdata/daysscraped2.csv')\n",
    "# daydf = pd.DataFrame(trackday_lists, columns=['track','year','month','day'])\n",
    "# daydf.to_csv('tempdata/daysscraped.csv')\n",
    "# del trackday_lists2, daydf2, trackday_lists, daydf\n",
    "\n",
    "# daydf = pd.read_csv('tempdata/old/daysscraped.csv')\n",
    "# daydf2 = pd.read_csv('tempdata/old/daysscraped2.csv')\n",
    "# daydf.drop(daydf.columns[0], axis=1, inplace=True)\n",
    "# daydf2.drop(daydf2.columns[0], axis=1, inplace=True)\n",
    "# bigdaydf = pd.concat([daydf, daydf2])\n",
    "# bigdaydf.to_csv('tempdata/alldays.csv')\n",
    "# bigdaydf.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AQU</td>\n",
       "      <td>1998</td>\n",
       "      <td>10</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AQU</td>\n",
       "      <td>1998</td>\n",
       "      <td>10</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AQU</td>\n",
       "      <td>1998</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AQU</td>\n",
       "      <td>1998</td>\n",
       "      <td>10</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AQU</td>\n",
       "      <td>1998</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  track  year  month  day\n",
       "0   AQU  1998     10   28\n",
       "1   AQU  1998     10   29\n",
       "2   AQU  1998     10   30\n",
       "3   AQU  1998     10   31\n",
       "4   AQU  1998     11    1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigdaydf = pd.read_csv('tempdata/alldays.csv')\n",
    "bigdaydf = bigdaydf[bigdaydf.columns[-4:]]\n",
    "bigdaydf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Aqueduct', 'Arlington Park', 'Australian Racing', 'Australian Racing - B', 'Australian Racing - C', 'Bay Meadows', 'Belmont Park', 'Beulah Park', 'Calder Race Course', 'Camarero', 'Canterbury Park', 'Charles Town', 'Churchill Downs', 'Colonial Downs', 'Delta Downs', 'Del Mar', 'Delaware Park', 'Ellis Park', 'Emerald Downs', 'Evangeline Downs', 'Fair Grounds', 'Fairmount Park', 'Fairplex', 'Finger Lakes', 'Fort Erie', 'Golden Gate', 'Great Britain 1', 'Great Britain 2', 'Great Lakes Downs', 'Gulfstream Park', 'Hastings Park', 'Hawthorne Park', 'Hollywood Park', 'Hoosier Park', 'Indiana Downs\\n', 'Keeneland', 'Kentucky Downs', 'Laurel Park', 'Louisiana Downs', 'Lone Star Park', 'Los Alamitos', 'Meadowlands', 'Monmouth Park', 'Mountaineer Park', 'Northern California Fairs', 'Oaklawn Park', 'Penn National', 'Philadelphia Park', 'Pimlico', 'Portland Meadows ', 'Prairie Meadows', 'Remington Park', 'Retama Park', 'River Downs', 'Sam Houston', 'Santa Anita', 'Saratoga', 'South Africa1', 'South Africa 2', \"Sportsman's Park\", 'Suffolk Downs', 'Tampa Bay Downs', 'Thistledown', 'Timonium', 'Turf Paradise', 'Turfway Park', 'Woodbine']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['AQU', 'ARL', 'AU1', 'AU2', 'BAY', 'BEL', 'BEU', 'CAL', 'CAN',\n",
       "       'CHU', 'COL', 'CTN', 'DDN', 'DEL', 'DPK', 'ELL', 'EMD', 'EVN',\n",
       "       'FGD', 'FLK', 'FLX', 'FMT', 'FTE', 'GB1', 'GLD', 'GOL', 'GUL',\n",
       "       'HAS', 'HAW', 'HOO', 'HPX', 'IND', 'KEN', 'KND', 'LAU', 'LDN',\n",
       "       'LON', 'LOS', 'MDL', 'MON', 'MTR', 'NCF', 'OAK', 'PAR', 'PEN',\n",
       "       'PHI', 'PIM', 'PRM', 'REM', 'RET', 'RIV', 'SAM', 'SAN', 'SGA',\n",
       "       'SPT', 'SUF', 'TAM', 'THI', 'TIM', 'TUR', 'WOB', 'ZA1', 'ZA2'], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print tracks\n",
    "bigdaydf.track.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(83873, 4)\n",
      "(103170, 4)\n"
     ]
    }
   ],
   "source": [
    "bigdaydf = bigdaydf.set_index(bigdaydf['track'])\n",
    "usadaydf = bigdaydf.drop(['GB1','ZA1','ZA2','AU1','AU2','FTE','HAS','NCF','WOB'])\n",
    "print usadaydf.shape\n",
    "print bigdaydf.shape\n",
    "usadaydf.to_csv('tempdata/usadays.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AQU</td>\n",
       "      <td>1998</td>\n",
       "      <td>10</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AQU</td>\n",
       "      <td>1998</td>\n",
       "      <td>10</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AQU</td>\n",
       "      <td>1998</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AQU</td>\n",
       "      <td>1998</td>\n",
       "      <td>10</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AQU</td>\n",
       "      <td>1998</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  track  year  month  day\n",
       "0   AQU  1998     10   28\n",
       "1   AQU  1998     10   29\n",
       "2   AQU  1998     10   30\n",
       "3   AQU  1998     10   31\n",
       "4   AQU  1998     11    1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usadaydf = pd.read_csv('tempdata/usadays.csv')\n",
    "usadaydf.drop('track.1',axis=1, inplace=True)\n",
    "usadaydf.head() #<--this is the one we want!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract(table):\n",
    "    rows = table.findAll('tr')\n",
    "    racenum = rows[0].findAll('td')[1].text\n",
    "    if len(racenum) > 2:\n",
    "        return 'faketable'\n",
    "    print table\n",
    "    \n",
    "    return [racenum,]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1e+03 ns, sys: 0 ns, total: 1e+03 ns\n",
      "Wall time: 3.81 µs\n",
      "(83873, 4)CPU times: user 1e+03 ns, sys: 0 ns, total: 1e+03 ns\n",
      "Wall time: 3.81 µs\n",
      "(83873, 4)CPU times: user 1e+03 ns, sys: 0 ns, total: 1e+03 ns\n",
      "Wall time: 3.81 µs\n",
      "(83873, 4)\n",
      "Made it 101\n",
      "Made it 101\n",
      "Made it 101\n",
      "Made it 10001\n",
      "Made it 10001\n",
      "Made it 10001\n",
      "Made it 20001\n",
      "Made it 20001\n",
      "Made it 20001\n",
      "Made it 30001\n",
      "Made it 30001\n",
      "Made it 30001\n",
      "Made it 40001\n",
      "Made it 40001\n",
      "Made it 40001\n",
      "Made it 50001\n",
      "Made it 50001\n",
      "Made it 50001\n",
      "Made it 60001\n",
      "Made it 60001\n",
      "Made it 60001\n",
      "Made it 70001\n",
      "Made it 70001\n",
      "Made it 70001\n",
      "Made it 80001\n",
      "Made it 80001\n",
      "Made it 80001\n",
      "Home stretch!!!\n",
      "\n",
      "Home stretch!!!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AQU</td>\n",
       "      <td>1998</td>\n",
       "      <td>10</td>\n",
       "      <td>28</td>\n",
       "      <td>[&lt;table bgcolor=\"FF,FF,FF\" border=\"0\"&gt;\n",
       "&lt;tr&gt;\n",
       "&lt;t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AQU</td>\n",
       "      <td>1998</td>\n",
       "      <td>10</td>\n",
       "      <td>29</td>\n",
       "      <td>[&lt;table bgcolor=\"FF,FF,FF\" border=\"0\"&gt;\n",
       "&lt;tr&gt;\n",
       "&lt;t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AQU</td>\n",
       "      <td>1998</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>[&lt;table bgcolor=\"FF,FF,FF\" border=\"0\"&gt;\n",
       "&lt;tr&gt;\n",
       "&lt;t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AQU</td>\n",
       "      <td>1998</td>\n",
       "      <td>10</td>\n",
       "      <td>31</td>\n",
       "      <td>[&lt;table bgcolor=\"FF,FF,FF\" border=\"0\"&gt;\n",
       "&lt;tr&gt;\n",
       "&lt;t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AQU</td>\n",
       "      <td>1998</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1   2   3                                                  4\n",
       "0  AQU  1998  10  28  [<table bgcolor=\"FF,FF,FF\" border=\"0\">\n",
       "<tr>\n",
       "<t...\n",
       "1  AQU  1998  10  29  [<table bgcolor=\"FF,FF,FF\" border=\"0\">\n",
       "<tr>\n",
       "<t...\n",
       "2  AQU  1998  10  30  [<table bgcolor=\"FF,FF,FF\" border=\"0\">\n",
       "<tr>\n",
       "<t...\n",
       "3  AQU  1998  10  31  [<table bgcolor=\"FF,FF,FF\" border=\"0\">\n",
       "<tr>\n",
       "<t...\n",
       "4  AQU  1998  11   1                                                 []"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AQU</td>\n",
       "      <td>1998</td>\n",
       "      <td>10</td>\n",
       "      <td>28</td>\n",
       "      <td>[&lt;table bgcolor=\"FF,FF,FF\" border=\"0\"&gt;\n",
       "&lt;tr&gt;\n",
       "&lt;t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AQU</td>\n",
       "      <td>1998</td>\n",
       "      <td>10</td>\n",
       "      <td>29</td>\n",
       "      <td>[&lt;table bgcolor=\"FF,FF,FF\" border=\"0\"&gt;\n",
       "&lt;tr&gt;\n",
       "&lt;t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AQU</td>\n",
       "      <td>1998</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>[&lt;table bgcolor=\"FF,FF,FF\" border=\"0\"&gt;\n",
       "&lt;tr&gt;\n",
       "&lt;t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AQU</td>\n",
       "      <td>1998</td>\n",
       "      <td>10</td>\n",
       "      <td>31</td>\n",
       "      <td>[&lt;table bgcolor=\"FF,FF,FF\" border=\"0\"&gt;\n",
       "&lt;tr&gt;\n",
       "&lt;t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AQU</td>\n",
       "      <td>1998</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1   2   3                                                  4\n",
       "0  AQU  1998  10  28  [<table bgcolor=\"FF,FF,FF\" border=\"0\">\n",
       "<tr>\n",
       "<t...\n",
       "1  AQU  1998  10  29  [<table bgcolor=\"FF,FF,FF\" border=\"0\">\n",
       "<tr>\n",
       "<t...\n",
       "2  AQU  1998  10  30  [<table bgcolor=\"FF,FF,FF\" border=\"0\">\n",
       "<tr>\n",
       "<t...\n",
       "3  AQU  1998  10  31  [<table bgcolor=\"FF,FF,FF\" border=\"0\">\n",
       "<tr>\n",
       "<t...\n",
       "4  AQU  1998  11   1                                                 []"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Home stretch!!!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AQU</td>\n",
       "      <td>1998</td>\n",
       "      <td>10</td>\n",
       "      <td>28</td>\n",
       "      <td>[&lt;table bgcolor=\"FF,FF,FF\" border=\"0\"&gt;\n",
       "&lt;tr&gt;\n",
       "&lt;t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AQU</td>\n",
       "      <td>1998</td>\n",
       "      <td>10</td>\n",
       "      <td>29</td>\n",
       "      <td>[&lt;table bgcolor=\"FF,FF,FF\" border=\"0\"&gt;\n",
       "&lt;tr&gt;\n",
       "&lt;t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AQU</td>\n",
       "      <td>1998</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>[&lt;table bgcolor=\"FF,FF,FF\" border=\"0\"&gt;\n",
       "&lt;tr&gt;\n",
       "&lt;t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AQU</td>\n",
       "      <td>1998</td>\n",
       "      <td>10</td>\n",
       "      <td>31</td>\n",
       "      <td>[&lt;table bgcolor=\"FF,FF,FF\" border=\"0\"&gt;\n",
       "&lt;tr&gt;\n",
       "&lt;t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AQU</td>\n",
       "      <td>1998</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1   2   3                                                  4\n",
       "0  AQU  1998  10  28  [<table bgcolor=\"FF,FF,FF\" border=\"0\">\n",
       "<tr>\n",
       "<t...\n",
       "1  AQU  1998  10  29  [<table bgcolor=\"FF,FF,FF\" border=\"0\">\n",
       "<tr>\n",
       "<t...\n",
       "2  AQU  1998  10  30  [<table bgcolor=\"FF,FF,FF\" border=\"0\">\n",
       "<tr>\n",
       "<t...\n",
       "3  AQU  1998  10  31  [<table bgcolor=\"FF,FF,FF\" border=\"0\">\n",
       "<tr>\n",
       "<t...\n",
       "4  AQU  1998  11   1                                                 []"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### RUN THESE EXACT LINES GEORGE\n",
    "%time\n",
    "usadaydf = pd.read_csv('tempdata/usadays.csv')\n",
    "usadaydf.drop('track.1',axis=1, inplace=True)\n",
    "#usadaydf.head() #<--this is the one we want!!!! use this to check too\n",
    "print usadaydf.shape # this should be like 83000\n",
    "exceptions = []\n",
    "superout = []\n",
    "acc = 0\n",
    "livee = True\n",
    "live1 = True\n",
    "live2 = True\n",
    "live3 = True\n",
    "live4 = True\n",
    "live5 = True\n",
    "live6 = True\n",
    "live7 = True\n",
    "live8 = True\n",
    "live9 = True\n",
    "for tup in usadaydf.itertuples():\n",
    "    time.sleep(0.8)\n",
    "    magiclink = 'https://www.racingchannel.com/archives/{}/{}/{}/{}{}{}{}.HTM'\\\n",
    "        .format(tup[1],tup[2],tup[3],tup[1],str(tup[2])[2:],tup[3],tup[4])\n",
    "    try:\n",
    "        racetest = requests.get(magiclink).text\n",
    "        soup = BeautifulSoup(racetest, 'html.parser').html.body\n",
    "        meat = soup.findAll('table')\n",
    "        superout.append([tup[1],tup[2],tup[3],tup[4],meat])\n",
    "    except:\n",
    "        exceptions.append(tup[1],tup[2],tup[3],tup[4],meat)\n",
    "    acc += 1\n",
    "    if acc > 100 and livee:\n",
    "        livee = False\n",
    "        print \"Made it {}\".format(acc)\n",
    "    elif acc > 10000 and live1:\n",
    "        live1 = False\n",
    "        print \"Made it {}\".format(acc)\n",
    "    elif acc > 20000 and live2:\n",
    "        live2 = False\n",
    "        print \"Made it {}\".format(acc)\n",
    "    elif acc > 30000 and live3:\n",
    "        live3 = False\n",
    "        print \"Made it {}\".format(acc)\n",
    "    elif acc > 40000 and live4:\n",
    "        live4 = False\n",
    "        print \"Made it {}\".format(acc)\n",
    "    elif acc > 50000 and live5:\n",
    "        live5 = False\n",
    "        print \"Made it {}\".format(acc)\n",
    "    elif acc > 60000 and live6:\n",
    "        live6 = False\n",
    "        print \"Made it {}\".format(acc)\n",
    "    elif acc > 70000 and live7:\n",
    "        live7 = False\n",
    "        print \"Made it {}\".format(acc)\n",
    "    elif acc > 80000 and live8:\n",
    "        live8 = False\n",
    "        print \"Made it {}\".format(acc)\n",
    "        print \"Home stretch!!!\"  \n",
    "    \n",
    "\n",
    "superdf = pd.DataFrame(superout)\n",
    "superdf.to_csv('tempdata/superdf.csv')\n",
    "excepdf = pd.DataFrame(exceptions)\n",
    "excepdf.to_csv('tempdata/excepdf.csv')\n",
    "superdf.head()\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "#     for table in meat:\n",
    "#         try:\n",
    "#             extract(table)\n",
    "#         except:\n",
    "#             exceptions.append([table,tup])\n",
    "#         break\n",
    "#     print exceptions\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tables = soup.findAll('tr')\n",
    "# print len(tables)\n",
    "# for elem in tables[:6]:\n",
    "#     print elem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 1) first populate \"inlsts\" with all the trackkeys, years, months, and days\n",
    "# 2) scrape each page for its html\n",
    "# 3) rip through the html for the info we want\n",
    "# 4) format the info into what we're feeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "superdf = pd.read_csv(\"~/Desktop/superdf.csv\")\n",
    "superdf = superdf[superdf.columns[-5:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<new>asdf</new>', '<yeet>asdfaghfds,FF<yeet>', '<FF>masdfasdf</FF>']\n"
     ]
    }
   ],
   "source": [
    "def stringtolist(string):\n",
    "    elems = []\n",
    "    curr = ''\n",
    "    acc = 0\n",
    "    for char in list(string):\n",
    "        if char in '[':\n",
    "            pass\n",
    "        elif (char == ',' and list(string)[acc-1] in '>') or (char == ']'):\n",
    "            elems.append(curr)\n",
    "            curr = ''\n",
    "        else:\n",
    "            curr += char\n",
    "        acc += 1\n",
    "    return elems\n",
    "a = '[<new>asdf</new>,<yeet>asdfaghfds,FF<yeet>,<FF>masdfasdf</FF>]'\n",
    "print stringtolist(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      "CURVY IMAGE\n",
      "MILLIONDOLLARSMILE\n",
      "ROOK\n",
      "WAPO\n",
      "FUNNY TOY (ARG)\n",
      "RUBY RUBLES\n",
      "EXCHANGE PLACE\n",
      "EARLY WARNING\n",
      "JET BLACK\n",
      "----\n",
      "CRITICS ACCLAIM\n",
      "STORM IMP\n",
      "BETTER THAN HONOUR\n",
      "BUNDLING\n",
      "SANFORD SAM\n",
      "LE MISTRAL\n",
      "PHONE THE KING\n",
      "BRAC DRIFTER\n",
      "HANDEL\n",
      "----\n",
      "DR. CHABOT\n",
      "MAWHUB\n",
      "LATE CARSON\n",
      "BIG NEWS\n",
      "RETIRING DON\n",
      "COMIC PROSPECT\n",
      "SOLAR COLONY\n",
      "WILDFAREL\n",
      "HIP HAPPY HIP\n",
      "----\n",
      "SILVER KIPPER\n",
      "\n",
      "CAJUN SEASON\n",
      "CIGAR CHARLIE\n",
      "CAYMAN CAT\n",
      "\n",
      "\n",
      "SNIT\n",
      "\n",
      "CARROM\n",
      "----\n",
      "SILVER KIPPER\n",
      "\n",
      "CAJUN SEASON\n",
      "CIGAR CHARLIE\n",
      "CAYMAN CAT\n",
      "\n",
      "\n",
      "SNIT\n",
      "\n",
      "CARROM\n",
      "----\n",
      "SILVER KIPPER\n",
      "\n",
      "CAJUN SEASON\n",
      "CIGAR CHARLIE\n",
      "CAYMAN CAT\n",
      "\n",
      "\n",
      "SNIT\n",
      "\n",
      "CARROM\n",
      "----\n",
      "SILVER KIPPER\n",
      "\n",
      "CAJUN SEASON\n",
      "CIGAR CHARLIE\n",
      "CAYMAN CAT\n",
      "\n",
      "\n",
      "SNIT\n",
      "\n",
      "CARROM\n",
      "----\n",
      "SILVER KIPPER\n",
      "\n",
      "CAJUN SEASON\n",
      "CIGAR CHARLIE\n",
      "CAYMAN CAT\n",
      "\n",
      "\n",
      "SNIT\n",
      "\n",
      "CARROM\n",
      "----\n",
      "SILVER KIPPER\n",
      "\n",
      "CAJUN SEASON\n",
      "CIGAR CHARLIE\n",
      "CAYMAN CAT\n",
      "\n",
      "\n",
      "SNIT\n",
      "\n",
      "CARROM\n",
      "----\n",
      "SILVER KIPPER\n",
      "\n",
      "CAJUN SEASON\n",
      "CIGAR CHARLIE\n",
      "CAYMAN CAT\n",
      "\n",
      "\n",
      "SNIT\n",
      "\n",
      "CARROM\n",
      "----\n",
      "CASCADE HALO\n",
      "GOLD 'N SUGAR\n",
      "MS. CALABASH\n",
      "DREWS TOUCH\n",
      "GOLD CERTIFICATE\n",
      "SIMUD (CHI)\n",
      "COUNT ON STEVE\n",
      "WOULDN'T WE ALL\n",
      "MR. SINATRA\n",
      "\n",
      "----\n",
      "DOUBLE CONQUEST\n",
      "RAINSTICK\n",
      "BUFFALO SUE\n",
      "GO IT ALONE\n",
      "REPORT ON RAIN\n",
      "LEGAL STREET\n",
      "RUMPIPUMPY (GB)\n",
      "MR. GROUSH\n",
      "REGAL RUBY\n",
      "----\n",
      "PRO RULER\n",
      "REPRESENT\n",
      "STRIKE IT LUCKY\n",
      "SWAMP\n",
      "COYOTE LAKES\n",
      "STROLLING BELLE\n",
      "ADRIAN\n",
      "BAYTOWN\n",
      "GET THE SAINT\n",
      "----\n",
      "ESPRESSO\n",
      "ANTHENIAN THUNDER\n",
      "JANE\n",
      "GOODTHINGSTOCOME\n",
      "HOMAH SAV\n",
      "CORETTA (IRE)\n",
      "TOP OFFICIAL\n",
      "YOKAMA\n",
      "----\n",
      "SWEEPING NEW DAWN\n",
      "PISTOL PACKN ANNIE\n",
      "HOPE CHEST\n",
      "ATTITUDE\n",
      "\n",
      "SHUT OUT TIME\n",
      "COMPASSIONATE\n",
      "LONG DISTANCE\n",
      "DANIELLE'S HALO\n",
      "----\n",
      "GRANDPA ED\n",
      "TICKLE MY PASSION\n",
      "OUTLANDISH\n",
      "ALEXTHETHIRD\n",
      "REPORT ON RAIN\n",
      "MY SUCCESS\n",
      "SHOOP\n",
      "DANCES IN SNOW\n",
      "ONAMISSIONFROMGOD\n",
      "----\n",
      "TIME OFF\n",
      "LISTEN TO ME\n",
      "NO MORE JEFF\n",
      "CASABLANCA\n",
      "DEMI'S BRET\n",
      "DR. DISTINCTIVE\n",
      "BROOMESSE\n",
      "MEMORIES OF GOLD\n",
      "COPELAN'S PACHE\n",
      "----\n",
      "TWO PUTT\n",
      "T STORM\n",
      "JADED MONEY\n",
      "LOVELY AND PROUD\n",
      "GLAMOUR GIRL\n",
      "DEMONS CLOUD\n",
      "SANTARIA\n",
      "EXCHANGE PLACE\n",
      "IRON GAVEL\n",
      "----\n",
      "GLORIANA\n",
      "HIGH RIDGE\n",
      "SIGN OF COURAGE\n",
      "BRUTALLY FRANK\n",
      "GOLDEN DICE\n",
      "FLAX JACKET\n",
      "FOIL\n",
      "MUSICAL GHOST\n",
      "SANFORD SAM\n",
      "----\n",
      "STAR MINER\n",
      "WINDSWEPT BLUES\n",
      "BELLE BOYD\n",
      "NUDGE\n",
      "GOOD SKATE\n",
      "FANTACULAR\n",
      "PREMIER KRISCHIEF\n",
      "PAULA'S GIRL\n",
      "LETTHEDREAMBEGIN\n"
     ]
    }
   ],
   "source": [
    "errortups = []\n",
    "\n",
    "\n",
    "count = 0\n",
    "allthethings = []\n",
    "for tup in superdf.itertuples():\n",
    "    count += 1\n",
    "    if count > 20:\n",
    "        break\n",
    "    elif tup[-1] == '[]':\n",
    "        errortups.append(tup[:4])\n",
    "    else:\n",
    "        tables = [BeautifulSoup(elem).html.body.table for elem in stringtolist(tup[-1])]\n",
    "        infos1 = []\n",
    "        infos2 = []\n",
    "        infos3 = []\n",
    "        othercrap = []\n",
    "        others3 = []\n",
    "        for table in tables:\n",
    "            boldys = []\n",
    "            numsiwant = []\n",
    "            for td in table.findAll('td'):\n",
    "                bolds = td.findAll('b')\n",
    "                if len(bolds) > 0:\n",
    "                    boldys.append(bolds[0].text.encode('ascii'))\n",
    "                if td.get('align') == 'RIGHT' and '<b>' not in str(td):\n",
    "                    content = td.text.encode('ascii')\n",
    "                    if content != '':\n",
    "                        numsiwant.append(content)\n",
    "            infopack3 = numsiwant[:6]\n",
    "            infos3.append(infopack3)\n",
    "            other3 = numsiwant[6:]\n",
    "            others3.append(other3)\n",
    "            try:\n",
    "                infopack1 = [boldys[1],boldys[6],boldys[7],boldys[9],boldys[10],boldys[12],boldys[13]]\n",
    "                infopack2 = boldys[14:]\n",
    "                infos1.append(infopack1)\n",
    "                infos2.append(infopack2)\n",
    "            except:\n",
    "                #print \"index error %i\" % len(infopack1)\n",
    "                othercrap.append((boldys,table))\n",
    "    allthethings.append([infos1,infos2,infos3,others3,othercrap])\n",
    "\n",
    "#         print tup[:4]\n",
    "#         for i in range(len(infos1)):\n",
    "#             print infos1[i]\n",
    "#             print infos2[i]\n",
    "#             print infos3[i]\n",
    "#         print '\\n'\n",
    "#         print others3\n",
    "#         print othercrap\n",
    "#         print '\\n\\n\\n'\n",
    "\n",
    "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # \n",
    "\n",
    "class RaceDataSet(object):\n",
    "    \n",
    "    def __init__(self, num):\n",
    "        self.num = num\n",
    "        self.first = None\n",
    "        self.second = None\n",
    "        self.third = None\n",
    "        self.firstnum = None\n",
    "        self.secondnum = None\n",
    "        self.thirdnum = None\n",
    "        self.win = None\n",
    "        self.place1 = None\n",
    "        self.place2 = None\n",
    "        self.show1 = None\n",
    "        self.show2 = None\n",
    "        self.show3 = None\n",
    "        self.otherstuff = []\n",
    "\n",
    "alldays = []\n",
    "for day in allthethings:\n",
    "    races = []\n",
    "    for i in range(len(day[0])):\n",
    "        infopack = day[0][i]\n",
    "        #print infopack\n",
    "        racedata = RaceDataSet(infopack[0])\n",
    "        racedata.firstnum = infopack[1]\n",
    "        racedata.first = infopack[2]\n",
    "        racedata.secondnum = infopack[3]\n",
    "        racedata.second = infopack[4]\n",
    "        racedata.thirdnum = infopack[5]\n",
    "        racedata.third = infopack[6]\n",
    "        races.append(racedata)\n",
    "    alldays.append(races)\n",
    "for day in alldays:\n",
    "    print \"----\"\n",
    "    for race in day:\n",
    "        print race.first\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
